import csv
import mimetypes
from pathlib import Path

import pytest

from covidhub.config import AlternateGDriveConfig
from covidhub.google.drive import (
    DriveObject,
    DriveService,
    get_contents_by_folder_id,
    get_file_by_name,
    mkdir_recursive,
    put_file,
)
from qpcr_processing.conftest import credentials_for_tests
from qpcr_processing.processing import processing

PROJECT_DIR = Path(__file__).parent.parent.parent.parent
EXAMPLE_FILE_DIR = PROJECT_DIR / "example_files"


LOG_FILES = [
    "D041758_All Wells -  Quantification Amplification Results_FAM.csv",
    "D041758_All Wells -  Quantification Cq Results.csv",
    "D041758_All Wells - Run Information.csv",
    "D041761_All Wells -  Quantification Amplification Results_FAM.csv",
    "D041761_All Wells -  Quantification Amplification Results_HEX.csv",
    "D041761_All Wells -  Quantification Cq Results.csv",
    "D041761_All Wells - Run Information.csv",
    "B131885_All Wells - Run Information.csv",
    "B131885_All Wells -  Quantification Cq Results.csv",
    "B131885_All Wells -  Quantification Amplification Results_HEX.csv",
    "B131885_All Wells -  Quantification Amplification Results_FAM.csv",
]


PLATE_LAYOUT_FILES = [
    "96sample_plate_accessions_SP000002.xlsx",
    "20200319-174657_SP000001_tube_to_plate.csv",
    "96sample_plate_accessions_SP000214.xlsx",
]


EXPECTED_CSV_FILES = {
    "SP000001-D041758_cb_results.csv": "SP000001-D041758_cb_results-for-comparison.csv",
    "SP000002-D041761_cb_results.csv": "SP000002-D041761_cb_results-for-comparison.csv",
    "SP000214-B131885_cb_results.csv": "SP000214-B131885_cb_results-for-comparison.csv",
}
"""Maps between the output CSV filename and the path to find the expected result."""


EXPECTED_MARKERS = {"D041758", "D041761", "B131885"}
"""The marker files that should be generated by successful processing."""


EXPECTED_PDFS = {
    "SP000001-D041758_final.pdf",
    "SP000002-D041761_final.pdf",
    "SP000214-B131885_final.pdf",
}
"""The PDF reports that should be generated by successful processing."""


def file_mode(filename: str) -> str:
    """Given a filename, return the mode it should be opened with ("b" if binary,
    "" otherwise)
    """
    content_type = mimetypes.guess_type(filename)[0] or "application/octet-stream"
    return "" if content_type.startswith("text/") else "b"


@pytest.mark.full_processing
def test_processing(gdrive_service: DriveService, gdrive_folder: DriveObject):
    """Test to validate the gdrive processing pipeline.  This test has four phases:
    1. Create directories on a test gdrive space for the files that are staged.
    2. Stage the files so that it mimics the production environment.  This includes
       the logs, the plate layout files, and the control layout files.
    3. Run the main processsing loop.
    4. Verify that the output csv files are correct.
    5. Verify that the expected markers and PDFs are present.

    If this test fails, verify that all the data necessary to run the pipeline is staged
    correctly."""

    ####################################################################################
    # STEP 1: Create directories on a test gdrive space for the files that are staged.

    # set up the test space
    cfg = AlternateGDriveConfig(gdrive_folder.name)

    # make the necessary input folders
    logs_folder_id = mkdir_recursive(gdrive_service, "root", cfg.PCR_LOGS_FOLDER)
    plate_layout_folder_id = mkdir_recursive(
        gdrive_service, "root", cfg.PLATE_LAYOUT_FOLDER
    )

    # make the necessary output folders
    mkdir_recursive(gdrive_service, "root", cfg.CSV_RESULTS_FOLDER)
    cb_csv_folder_id = mkdir_recursive(
        gdrive_service, "root", cfg.CHINA_BASIN_CSV_REPORTS_FOLDER
    )
    final_results_folder_id = mkdir_recursive(
        gdrive_service, "root", cfg.FINAL_REPORTS_FOLDER
    )
    markers_folder_id = mkdir_recursive(gdrive_service, "root", cfg.PCR_MARKERS_FOLDER)

    ####################################################################################
    # STEP 2: Stage the files.

    # copy all the files to the appropriate places
    for filename in LOG_FILES:
        mode = f"r{file_mode(filename)}"
        with (EXAMPLE_FILE_DIR / filename).open(mode) as src_fh, put_file(
            gdrive_service, logs_folder_id, filename
        ) as dst_fh:
            dst_fh.write(src_fh.read())

    for filename in PLATE_LAYOUT_FILES:
        mode = f"r{file_mode(filename)}"
        with (EXAMPLE_FILE_DIR / filename).open(mode) as src_fh, put_file(
            gdrive_service, plate_layout_folder_id, filename
        ) as dst_fh:
            dst_fh.write(src_fh.read())

    ####################################################################################
    # STEP 3: Run the processing pipeline

    processing(cfg, credentials_for_tests())

    ####################################################################################
    # STEP 4: Verify the csv files.

    for remote_filename, local_filename in EXPECTED_CSV_FILES.items():
        with (EXAMPLE_FILE_DIR / local_filename).open("r") as t1, get_file_by_name(
            gdrive_service, cb_csv_folder_id, remote_filename
        ) as t2:
            rdr1 = csv.reader(t1)
            rdr2 = csv.reader(t2)
            for row1, row2, in zip(rdr1, rdr2):
                assert (
                    row1 == row2
                ), f"mismatch between {local_filename} and {remote_filename}"

    ####################################################################################
    # STEP 5: Verify that markers and PDFs were created and uploaded

    marker_folder_contents = get_contents_by_folder_id(
        gdrive_service, markers_folder_id, only_files=True
    )
    marker_set = {
        marker_folder_entry.name for marker_folder_entry in marker_folder_contents
    }

    assert marker_set == EXPECTED_MARKERS

    pdf_folder_contents = get_contents_by_folder_id(
        gdrive_service, final_results_folder_id, only_files=True
    )
    pdf_report_set = {pdf_folder_entry.name for pdf_folder_entry in pdf_folder_contents}

    assert pdf_report_set == EXPECTED_PDFS
